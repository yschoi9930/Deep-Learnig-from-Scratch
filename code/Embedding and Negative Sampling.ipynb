{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# word2vec 속도 개선"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embedding 계층"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-06T04:35:11.368887Z",
     "start_time": "2021-08-06T04:35:11.354487Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-06T06:52:53.275260Z",
     "start_time": "2021-08-06T06:52:53.251082Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  1,  2],\n",
       "       [ 3,  4,  5],\n",
       "       [ 6,  7,  8],\n",
       "       [ 9, 10, 11],\n",
       "       [12, 13, 14],\n",
       "       [15, 16, 17],\n",
       "       [18, 19, 20]])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W = np.arange(21).reshape(7,3)\n",
    "W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-06T04:35:52.446432Z",
     "start_time": "2021-08-06T04:35:52.425283Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([15, 16, 17])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-06T04:36:13.457679Z",
     "start_time": "2021-08-06T04:36:13.428505Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 3,  4,  5],\n",
       "       [ 0,  1,  2],\n",
       "       [ 9, 10, 11],\n",
       "       [ 0,  1,  2]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx = np.array([1,0,3,0])\n",
    "W[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-06T04:42:08.526804Z",
     "start_time": "2021-08-06T04:42:08.509036Z"
    }
   },
   "outputs": [],
   "source": [
    "class Embedding:\n",
    "    def __init__(self, W) :\n",
    "        self.params = [W] # 리스트 안에 담기\n",
    "        self.grads = [np.zeros_like(W)]\n",
    "    \n",
    "    def forward(self, idx) :\n",
    "        W, = self.params # 리스트  에서 해제\n",
    "        self.idx = idx\n",
    "        out = W[idx]\n",
    "        return out\n",
    "    \n",
    "#     def backward(self, dout):\n",
    "#         dW, = self.grads\n",
    "#         dW[...] = 0\n",
    "#         dw[self.idx] = dout\n",
    "#         return None\n",
    "# idx에 따라 중복할당이 될 수도 있기에 좋지 않은 방법\n",
    "\n",
    "def backward(self, dout):\n",
    "    dW = self.grads\n",
    "    dW[...]=0 # dW 모양유지하면서 원소들 0으로 대체\n",
    "    \n",
    "    for i, word_id in enumerate(self.idx):\n",
    "        dw[word_id] +=dout[i]\n",
    "        # 혹은\n",
    "        # np.add.at(dW, self.idx, dout)\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 다중분류에서 이진분류로, EmbeddingDot 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-06T06:18:10.143684Z",
     "start_time": "2021-08-06T06:18:10.121645Z"
    }
   },
   "outputs": [],
   "source": [
    "class EmbeddingDot :\n",
    "    def __init__(self,W):\n",
    "        self.embed = Embedding(W)\n",
    "        self.params = self.embed.params\n",
    "        self.grads = self.embed.grads\n",
    "        self.cache = None\n",
    "    \n",
    "    def forward(self, h, idx) :\n",
    "        target_W = self.embed.forward(idx)\n",
    "        out = np.sum(target_W * h, axis =1)\n",
    "        self.cache = (h, target_W)\n",
    "        return out\n",
    "    \n",
    "    def backward(self, dout):\n",
    "        h, target_W = self.cache\n",
    "        dout = dout.reshape(dout.shape[0],1)\n",
    "        dtarget_W = dout*h\n",
    "        self.embed.backward(dtarget_W)\n",
    "        dh = dout*target_W\n",
    "        return dh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 네거티브 샘플링"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 네거티브 샘플링 기법"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-06T06:19:36.963746Z",
     "start_time": "2021-08-06T06:19:36.946122Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.choice(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-06T06:19:38.478939Z",
     "start_time": "2021-08-06T06:19:38.460687Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.choice(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-06T06:22:42.780565Z",
     "start_time": "2021-08-06T06:22:42.758937Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hello'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = ['you','say','goodbye','I','hello','.']\n",
    "np.random.choice(words) # 실행할 때마다 바뀜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-06T06:21:05.964968Z",
     "start_time": "2021-08-06T06:21:05.949485Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['you', 'hello', 'you', 'I', 'say'], dtype='<U7')"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 5개만 무작위로 샘플링(중복있음)\n",
    "np.random.choice(words, size=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-06T06:21:30.394479Z",
     "start_time": "2021-08-06T06:21:30.370344Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['I', 'say', 'hello', 'you', 'goodbye'], dtype='<U7')"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.choice(words, size=5, replace = False) # 중복없음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-06T06:22:49.279760Z",
     "start_time": "2021-08-06T06:22:49.258393Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'you'"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 확률 분포에 따라 샘플링\n",
    "p = [0.5,0.1,0.05,0.2,0.05,0.1]\n",
    "np.random.choice(words,p=p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-06T06:26:21.318079Z",
     "start_time": "2021-08-06T06:26:21.288645Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.64196878 0.33150408 0.02652714]\n"
     ]
    }
   ],
   "source": [
    "# 확률분포에 0.75 제곱을 하는 것을 권장 -> 확률이 낮은 단어의 확률을 살짝 높여 버리지 않기 위해\n",
    "p = [0.7,0.29,0.01]\n",
    "new_p = np.power(p,0.75)\n",
    "new_p /= np.sum(new_p)\n",
    "print(new_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-06T06:53:26.818972Z",
     "start_time": "2021-08-06T06:53:26.799282Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.EmbeddingDot at 0x14cdda2f550>"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_size = 5\n",
    "embed_dot_layers = [EmbeddingDot(W) for _ in range(sample_size+1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 네거티브 샘플링 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-06T07:05:08.705516Z",
     "start_time": "2021-08-06T07:05:08.699541Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "from common import negative_sampling_layer\n",
    "from common.negative_sampling_layer import UnigramSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-06T07:05:27.477066Z",
     "start_time": "2021-08-06T07:05:27.459702Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 4]\n",
      " [0 1]\n",
      " [4 3]]\n"
     ]
    }
   ],
   "source": [
    "corpus = np.array([0,1,2,3,4,1,2,3])\n",
    "power = 0.75\n",
    "sample_size = 2\n",
    "sampler = UnigramSampler(corpus, power, sample_size)\n",
    "target = np.array([1,3,0])\n",
    "negative_sample = sampler.get_negative_sample(target)\n",
    "print(negative_sample)\n",
    "# 첫번째, 1이 아닌 애들, 두번째 3이 아닌 애들, 세번째 0이 아닌 애들 2개씩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-06T06:48:13.945333Z",
     "start_time": "2021-08-06T06:48:13.913818Z"
    }
   },
   "outputs": [],
   "source": [
    "class NegativeSamplingLoss :\n",
    "    def __init__(self, W, corpus, power = 0.75, sample_size = 5) : # 출력측 가중치 W, 부정적 예의 샘플링  횟수 sample_size\n",
    "        self.samp_size = sample_size\n",
    "        self.sampler=UnigramSampler(corpus, power, sample_size) # UnigramSampler 클래스 인스턴스 변수에 지정\n",
    "        self.loss_layers = [SigmoidWithLoss() for _ in range(sample_size+1)]\n",
    "        self.embed_dot_layers = [EmbeddingDot(W) for _ in range(sample_size+1)] \n",
    "        # sample size(부정) + target[긍정] 더한 개수 만큼 embed_dot_layers, loss_layer 층 생성\n",
    "        self.params, self.grads = [], []\n",
    "        self.params += layer.params\n",
    "        self.grads += layer.grads\n",
    "    \n",
    "    def forward(self, h, target) :\n",
    "        batch_size = target.shape[0]\n",
    "        negative_sample = self.sampler.get_negative_sample(target) \n",
    "        # UnigramSampler 클래스 내의 get~ 메서드 사용, target 외에 단어로 생플링 \n",
    "        \n",
    "        # 긍정적 예 순전파\n",
    "        score = self.embed_dot_layers[0].forward(h,target)\n",
    "        # 첫번째 층에서 target과 h 값 계산\n",
    "        correct_label = np.ones(batch_size, dtype = np.int32)\n",
    "        # batch size 만큼 1로 구성된 배열 생성\n",
    "        loss = self.loss_layers[0].forward(score, correct_label)\n",
    "        # 1값과 score 값 간의 차이(손실)계산\n",
    "        \n",
    "        # 부정적 예 순전파\n",
    "        negative_label = np.zeros(batch_size, dtype=np.int32)\n",
    "        # 오답은 0으로 구성된 배열 구성\n",
    "        for i in range(self,sample_size) :\n",
    "            negative_target = negative_sample[:,i]\n",
    "            score = self.embed_dot_layers[1+i].forward(h,negative_target)\n",
    "            loss += self.loss_layers[1+i].forward(score, negative_label)\n",
    "        \n",
    "        return loss\n",
    "    \n",
    "    def backward(self, dout=1):\n",
    "        dh = 0\n",
    "        for l0, l1 in zip(self.loss_layers, self.embed_dot_layers):\n",
    "            dscore = l0.backward(dout)\n",
    "            dh += l1.backward(dscore)\n",
    "            \n",
    "        return dh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 개선판 word2vec 학습"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CBOW 모델 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-06T08:48:34.155302Z",
     "start_time": "2021-08-06T08:48:34.142158Z"
    }
   },
   "outputs": [],
   "source": [
    "from common.layers import Embedding\n",
    "from common.negative_sampling_layer import NegativeSamplingLoss\n",
    "\n",
    "class CBOW :\n",
    "    def __init__(self, vocab_size, hidden_size, window_size, corpus) :\n",
    "        V,H = vocab_size, hidden_size\n",
    "        \n",
    "        # 가중치 초기화\n",
    "        W_in = 0.01 * np.random.randn(V,H).astype('f')\n",
    "        W_out = 0.01 * np.random.randn(V,H).astype('f') # 임베딩 계층을 거치기에 그대로 형태 유지\n",
    "        \n",
    "        # 계층 생성\n",
    "        self.in_layers = []\n",
    "        for i in range(2*window_size) : # 임베딩 계층을 2*windowsize 작성하여 in_layer에 보관\n",
    "            layer = Embedding(W_in) # 임베딩 계층 사용\n",
    "            self.in_layers.append(layer)\n",
    "        self.ns_loss = NegativeSamplingLoss(W_out, corpus, power=0.75, sample_size=5) # 네거티브 샘플링 및 손실 계층 생성\n",
    "        \n",
    "        # 모든 가중치와 기울기를 배열에 모은다\n",
    "        layers = self.in_layers + [self.ns_loss] # 임베딩계층 후에 네거티브 샘플링 계층 붙이기\n",
    "        self.params, self.grads = [], []\n",
    "        for layer in layers :\n",
    "            self.params +=layer.params\n",
    "            self.grads += layer.grads\n",
    "            \n",
    "        # 인스턴스 변수에 단어의 분산표현을 저장한다\n",
    "        self.word_vecs = W_in\n",
    "        \n",
    "    def forward(self, contexts, target) :\n",
    "        h =0\n",
    "        for i, layer in enumerate(self.in_layers):\n",
    "            h += layer.forward(contexts[:,i]) # 맥락 위치 인덱싱\n",
    "        h *= 1/ len(self.in_layers)\n",
    "        loss = self.ns_loss.forward(h,target)\n",
    "        return loss\n",
    "    \n",
    "    def backward(self, dout=1) :\n",
    "        dout = self.ns_loss.backward(dout)\n",
    "        dout *= 1/len(self.in_layers)\n",
    "        for layer in self.in_layers:\n",
    "            layer.backward(dout)\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-06T08:29:27.172531Z",
     "start_time": "2021-08-06T08:29:27.163213Z"
    }
   },
   "source": [
    "### CBOW 모델학습코드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-06T08:32:06.002242Z",
     "start_time": "2021-08-06T08:32:05.974142Z"
    }
   },
   "outputs": [],
   "source": [
    "sys.path.append('..')\n",
    "import pickle\n",
    "from common.trainer import Trainer\n",
    "from common. optimizer import Adam\n",
    "from common.util import create_contexts_target, to_cpu, to_gpu\n",
    "import ptb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-06T08:36:14.346361Z",
     "start_time": "2021-08-06T08:36:09.915076Z"
    }
   },
   "outputs": [],
   "source": [
    "# 하이퍼 파라미터 설정\n",
    "window_size = 5\n",
    "hidden_size = 100\n",
    "batch_size = 100\n",
    "max_epoch = 10\n",
    "\n",
    "# 데이터 읽기\n",
    "corpus, word_to_id, id_to_word = ptb.load_data('train')\n",
    "vocab_size = len(word_to_id)\n",
    "\n",
    "contexts, target = create_contexts_target(corpus, window_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-06T08:37:30.875611Z",
     "start_time": "2021-08-06T08:37:30.803284Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'aer': 0,\n",
       " 'banknote': 1,\n",
       " 'berlitz': 2,\n",
       " 'calloway': 3,\n",
       " 'centrust': 4,\n",
       " 'cluett': 5,\n",
       " 'fromstein': 6,\n",
       " 'gitano': 7,\n",
       " 'guterman': 8,\n",
       " 'hydro-quebec': 9,\n",
       " 'ipo': 10,\n",
       " 'kia': 11,\n",
       " 'memotec': 12,\n",
       " 'mlx': 13,\n",
       " 'nahb': 14,\n",
       " 'punts': 15,\n",
       " 'rake': 16,\n",
       " 'regatta': 17,\n",
       " 'rubens': 18,\n",
       " 'sim': 19,\n",
       " 'snack-food': 20,\n",
       " 'ssangyong': 21,\n",
       " 'swapo': 22,\n",
       " 'wachter': 23,\n",
       " '<eos>': 24,\n",
       " 'pierre': 25,\n",
       " '<unk>': 26,\n",
       " 'N': 27,\n",
       " 'years': 28,\n",
       " 'old': 29,\n",
       " 'will': 30,\n",
       " 'join': 31,\n",
       " 'the': 32,\n",
       " 'board': 33,\n",
       " 'as': 34,\n",
       " 'a': 35,\n",
       " 'nonexecutive': 36,\n",
       " 'director': 37,\n",
       " 'nov.': 38,\n",
       " 'mr.': 39,\n",
       " 'is': 40,\n",
       " 'chairman': 41,\n",
       " 'of': 42,\n",
       " 'n.v.': 43,\n",
       " 'dutch': 44,\n",
       " 'publishing': 45,\n",
       " 'group': 46,\n",
       " 'rudolph': 47,\n",
       " 'and': 48,\n",
       " 'former': 49,\n",
       " 'consolidated': 50,\n",
       " 'gold': 51,\n",
       " 'fields': 52,\n",
       " 'plc': 53,\n",
       " 'was': 54,\n",
       " 'named': 55,\n",
       " 'this': 56,\n",
       " 'british': 57,\n",
       " 'industrial': 58,\n",
       " 'conglomerate': 59,\n",
       " 'form': 60,\n",
       " 'asbestos': 61,\n",
       " 'once': 62,\n",
       " 'used': 63,\n",
       " 'to': 64,\n",
       " 'make': 65,\n",
       " 'kent': 66,\n",
       " 'cigarette': 67,\n",
       " 'filters': 68,\n",
       " 'has': 69,\n",
       " 'caused': 70,\n",
       " 'high': 71,\n",
       " 'percentage': 72,\n",
       " 'cancer': 73,\n",
       " 'deaths': 74,\n",
       " 'among': 75,\n",
       " 'workers': 76,\n",
       " 'exposed': 77,\n",
       " 'it': 78,\n",
       " 'more': 79,\n",
       " 'than': 80,\n",
       " 'ago': 81,\n",
       " 'researchers': 82,\n",
       " 'reported': 83,\n",
       " 'fiber': 84,\n",
       " 'unusually': 85,\n",
       " 'enters': 86,\n",
       " 'with': 87,\n",
       " 'even': 88,\n",
       " 'brief': 89,\n",
       " 'exposures': 90,\n",
       " 'causing': 91,\n",
       " 'symptoms': 92,\n",
       " 'that': 93,\n",
       " 'show': 94,\n",
       " 'up': 95,\n",
       " 'decades': 96,\n",
       " 'later': 97,\n",
       " 'said': 98,\n",
       " 'inc.': 99,\n",
       " 'unit': 100,\n",
       " 'new': 101,\n",
       " 'york-based': 102,\n",
       " 'corp.': 103,\n",
       " 'makes': 104,\n",
       " 'cigarettes': 105,\n",
       " 'stopped': 106,\n",
       " 'using': 107,\n",
       " 'in': 108,\n",
       " 'its': 109,\n",
       " 'although': 110,\n",
       " 'preliminary': 111,\n",
       " 'findings': 112,\n",
       " 'were': 113,\n",
       " 'year': 114,\n",
       " 'latest': 115,\n",
       " 'results': 116,\n",
       " 'appear': 117,\n",
       " 'today': 118,\n",
       " \"'s\": 119,\n",
       " 'england': 120,\n",
       " 'journal': 121,\n",
       " 'medicine': 122,\n",
       " 'forum': 123,\n",
       " 'likely': 124,\n",
       " 'bring': 125,\n",
       " 'attention': 126,\n",
       " 'problem': 127,\n",
       " 'an': 128,\n",
       " 'story': 129,\n",
       " 'we': 130,\n",
       " \"'re\": 131,\n",
       " 'talking': 132,\n",
       " 'about': 133,\n",
       " 'before': 134,\n",
       " 'anyone': 135,\n",
       " 'heard': 136,\n",
       " 'having': 137,\n",
       " 'any': 138,\n",
       " 'questionable': 139,\n",
       " 'properties': 140,\n",
       " 'there': 141,\n",
       " 'no': 142,\n",
       " 'our': 143,\n",
       " 'products': 144,\n",
       " 'now': 145,\n",
       " 'neither': 146,\n",
       " 'nor': 147,\n",
       " 'who': 148,\n",
       " 'studied': 149,\n",
       " 'aware': 150,\n",
       " 'research': 151,\n",
       " 'on': 152,\n",
       " 'smokers': 153,\n",
       " 'have': 154,\n",
       " 'useful': 155,\n",
       " 'information': 156,\n",
       " 'whether': 157,\n",
       " 'users': 158,\n",
       " 'are': 159,\n",
       " 'at': 160,\n",
       " 'risk': 161,\n",
       " 'james': 162,\n",
       " 'a.': 163,\n",
       " 'boston': 164,\n",
       " 'institute': 165,\n",
       " 'dr.': 166,\n",
       " 'led': 167,\n",
       " 'team': 168,\n",
       " 'from': 169,\n",
       " 'national': 170,\n",
       " 'medical': 171,\n",
       " 'schools': 172,\n",
       " 'harvard': 173,\n",
       " 'university': 174,\n",
       " 'spokeswoman': 175,\n",
       " 'very': 176,\n",
       " 'modest': 177,\n",
       " 'amounts': 178,\n",
       " 'making': 179,\n",
       " 'paper': 180,\n",
       " 'for': 181,\n",
       " 'early': 182,\n",
       " '1950s': 183,\n",
       " 'replaced': 184,\n",
       " 'different': 185,\n",
       " 'type': 186,\n",
       " 'billion': 187,\n",
       " 'sold': 188,\n",
       " 'company': 189,\n",
       " 'men': 190,\n",
       " 'worked': 191,\n",
       " 'closely': 192,\n",
       " 'substance': 193,\n",
       " 'died': 194,\n",
       " 'three': 195,\n",
       " 'times': 196,\n",
       " 'expected': 197,\n",
       " 'number': 198,\n",
       " 'four': 199,\n",
       " 'five': 200,\n",
       " 'surviving': 201,\n",
       " 'diseases': 202,\n",
       " 'including': 203,\n",
       " 'recently': 204,\n",
       " 'total': 205,\n",
       " 'malignant': 206,\n",
       " 'lung': 207,\n",
       " 'far': 208,\n",
       " 'higher': 209,\n",
       " 'rate': 210,\n",
       " 'striking': 211,\n",
       " 'finding': 212,\n",
       " 'those': 213,\n",
       " 'us': 214,\n",
       " 'study': 215,\n",
       " 'west': 216,\n",
       " 'mass.': 217,\n",
       " 'factory': 218,\n",
       " 'appears': 219,\n",
       " 'be': 220,\n",
       " 'highest': 221,\n",
       " 'western': 222,\n",
       " 'industrialized': 223,\n",
       " 'countries': 224,\n",
       " 'he': 225,\n",
       " 'plant': 226,\n",
       " 'which': 227,\n",
       " 'owned': 228,\n",
       " 'by': 229,\n",
       " '&': 230,\n",
       " 'co.': 231,\n",
       " 'under': 232,\n",
       " 'contract': 233,\n",
       " 'probably': 234,\n",
       " 'support': 235,\n",
       " 'argue': 236,\n",
       " 'u.s.': 237,\n",
       " 'should': 238,\n",
       " 'regulate': 239,\n",
       " 'class': 240,\n",
       " 'common': 241,\n",
       " 'kind': 242,\n",
       " 'found': 243,\n",
       " 'most': 244,\n",
       " 'other': 245,\n",
       " 'buildings': 246,\n",
       " 'one': 247,\n",
       " 'few': 248,\n",
       " 'nations': 249,\n",
       " 'does': 250,\n",
       " \"n't\": 251,\n",
       " 'standard': 252,\n",
       " 'regulation': 253,\n",
       " 'smooth': 254,\n",
       " 'fibers': 255,\n",
       " 'such': 256,\n",
       " 'classified': 257,\n",
       " 'according': 258,\n",
       " 't.': 259,\n",
       " 'professor': 260,\n",
       " 'vermont': 261,\n",
       " 'college': 262,\n",
       " 'easily': 263,\n",
       " 'rejected': 264,\n",
       " 'body': 265,\n",
       " 'explained': 266,\n",
       " 'july': 267,\n",
       " 'environmental': 268,\n",
       " 'protection': 269,\n",
       " 'agency': 270,\n",
       " 'imposed': 271,\n",
       " 'gradual': 272,\n",
       " 'ban': 273,\n",
       " 'virtually': 274,\n",
       " 'all': 275,\n",
       " 'uses': 276,\n",
       " 'almost': 277,\n",
       " 'remaining': 278,\n",
       " 'outlawed': 279,\n",
       " 'made': 280,\n",
       " 'areas': 281,\n",
       " 'particularly': 282,\n",
       " 'dusty': 283,\n",
       " 'where': 284,\n",
       " 'dumped': 285,\n",
       " 'large': 286,\n",
       " 'imported': 287,\n",
       " 'material': 288,\n",
       " 'into': 289,\n",
       " 'huge': 290,\n",
       " 'poured': 291,\n",
       " 'cotton': 292,\n",
       " 'mixed': 293,\n",
       " 'dry': 294,\n",
       " 'process': 295,\n",
       " 'described': 296,\n",
       " 'clouds': 297,\n",
       " 'blue': 298,\n",
       " 'dust': 299,\n",
       " 'hung': 300,\n",
       " 'over': 301,\n",
       " 'parts': 302,\n",
       " 'though': 303,\n",
       " 'fans': 304,\n",
       " 'area': 305,\n",
       " 'question': 306,\n",
       " 'some': 307,\n",
       " 'managers': 308,\n",
       " 'contracted': 309,\n",
       " 'phillips': 310,\n",
       " 'vice': 311,\n",
       " 'president': 312,\n",
       " 'human': 313,\n",
       " 'resources': 314,\n",
       " 'but': 315,\n",
       " 'you': 316,\n",
       " 'recognize': 317,\n",
       " 'these': 318,\n",
       " 'events': 319,\n",
       " 'took': 320,\n",
       " 'place': 321,\n",
       " 'bearing': 322,\n",
       " 'work': 323,\n",
       " 'force': 324,\n",
       " 'yields': 325,\n",
       " 'money-market': 326,\n",
       " 'mutual': 327,\n",
       " 'funds': 328,\n",
       " 'continued': 329,\n",
       " 'slide': 330,\n",
       " 'amid': 331,\n",
       " 'signs': 332,\n",
       " 'portfolio': 333,\n",
       " 'expect': 334,\n",
       " 'further': 335,\n",
       " 'declines': 336,\n",
       " 'interest': 337,\n",
       " 'rates': 338,\n",
       " 'average': 339,\n",
       " 'seven-day': 340,\n",
       " 'compound': 341,\n",
       " 'yield': 342,\n",
       " 'taxable': 343,\n",
       " 'tracked': 344,\n",
       " 'money': 345,\n",
       " 'fund': 346,\n",
       " 'report': 347,\n",
       " 'eased': 348,\n",
       " 'fraction': 349,\n",
       " 'point': 350,\n",
       " 'week': 351,\n",
       " 'ended': 352,\n",
       " 'tuesday': 353,\n",
       " 'assume': 354,\n",
       " 'reinvestment': 355,\n",
       " 'dividends': 356,\n",
       " 'current': 357,\n",
       " 'continues': 358,\n",
       " 'maturity': 359,\n",
       " \"'\": 360,\n",
       " 'investments': 361,\n",
       " 'day': 362,\n",
       " 'days': 363,\n",
       " 'longest': 364,\n",
       " 'since': 365,\n",
       " 'august': 366,\n",
       " 'donoghue': 367,\n",
       " 'longer': 368,\n",
       " 'maturities': 369,\n",
       " 'thought': 370,\n",
       " 'indicate': 371,\n",
       " 'declining': 372,\n",
       " 'because': 373,\n",
       " 'they': 374,\n",
       " 'permit': 375,\n",
       " 'retain': 376,\n",
       " 'relatively': 377,\n",
       " 'period': 378,\n",
       " 'shorter': 379,\n",
       " 'considered': 380,\n",
       " 'sign': 381,\n",
       " 'rising': 382,\n",
       " 'can': 383,\n",
       " 'capture': 384,\n",
       " 'sooner': 385,\n",
       " 'open': 386,\n",
       " 'only': 387,\n",
       " 'institutions': 388,\n",
       " 'stronger': 389,\n",
       " 'indicator': 390,\n",
       " 'watch': 391,\n",
       " 'market': 392,\n",
       " 'reached': 393,\n",
       " 'nevertheless': 394,\n",
       " 'editor': 395,\n",
       " 'may': 396,\n",
       " 'again': 397,\n",
       " 'down': 398,\n",
       " 'recent': 399,\n",
       " 'rises': 400,\n",
       " 'short-term': 401,\n",
       " 'six-month': 402,\n",
       " 'treasury': 403,\n",
       " 'bills': 404,\n",
       " 'monday': 405,\n",
       " 'auction': 406,\n",
       " 'example': 407,\n",
       " 'rose': 408,\n",
       " 'despite': 409,\n",
       " 'investors': 410,\n",
       " 'continue': 411,\n",
       " 'pour': 412,\n",
       " 'cash': 413,\n",
       " 'assets': 414,\n",
       " 'grew': 415,\n",
       " '$': 416,\n",
       " 'during': 417,\n",
       " 'typically': 418,\n",
       " 'money-fund': 419,\n",
       " 'beat': 420,\n",
       " 'comparable': 421,\n",
       " 'vary': 422,\n",
       " 'go': 423,\n",
       " 'after': 424,\n",
       " 'top': 425,\n",
       " 'currently': 426,\n",
       " 'yielding': 427,\n",
       " 'well': 428,\n",
       " 'dreyfus': 429,\n",
       " 'world-wide': 430,\n",
       " 'dollar': 431,\n",
       " 'had': 432,\n",
       " 'earlier': 433,\n",
       " 'invests': 434,\n",
       " 'heavily': 435,\n",
       " 'dollar-denominated': 436,\n",
       " 'securities': 437,\n",
       " 'overseas': 438,\n",
       " 'management': 439,\n",
       " 'fees': 440,\n",
       " 'boosts': 441,\n",
       " 'simple': 442,\n",
       " '30-day': 443,\n",
       " 'fell': 444,\n",
       " 'slid': 445,\n",
       " 'j.p.': 446,\n",
       " 'grace': 447,\n",
       " 'holds': 448,\n",
       " 'elected': 449,\n",
       " 'succeeds': 450,\n",
       " 'd.': 451,\n",
       " 'formerly': 452,\n",
       " 'resigned': 453,\n",
       " 'energy': 454,\n",
       " 'seven': 455,\n",
       " 'seats': 456,\n",
       " 'pacific': 457,\n",
       " 'first': 458,\n",
       " 'financial': 459,\n",
       " 'shareholders': 460,\n",
       " 'approved': 461,\n",
       " 'acquisition': 462,\n",
       " 'royal': 463,\n",
       " 'ltd.': 464,\n",
       " 'toronto': 465,\n",
       " 'share': 466,\n",
       " 'or': 467,\n",
       " 'million': 468,\n",
       " 'thrift': 469,\n",
       " 'holding': 470,\n",
       " 'expects': 471,\n",
       " 'obtain': 472,\n",
       " 'regulatory': 473,\n",
       " 'approval': 474,\n",
       " 'complete': 475,\n",
       " 'transaction': 476,\n",
       " 'year-end': 477,\n",
       " 'international': 478,\n",
       " 'completed': 479,\n",
       " 'sale': 480,\n",
       " 'controls': 481,\n",
       " 'operations': 482,\n",
       " 's.p': 483,\n",
       " 'italian': 484,\n",
       " 'state-owned': 485,\n",
       " 'interests': 486,\n",
       " 'mechanical': 487,\n",
       " 'engineering': 488,\n",
       " 'industry': 489,\n",
       " 'based': 490,\n",
       " 'ohio': 491,\n",
       " 'computerized': 492,\n",
       " 'systems': 493,\n",
       " 'employs': 494,\n",
       " 'people': 495,\n",
       " 'annual': 496,\n",
       " 'revenue': 497,\n",
       " 'federal': 498,\n",
       " 'government': 499,\n",
       " 'suspended': 500,\n",
       " 'sales': 501,\n",
       " 'savings': 502,\n",
       " 'bonds': 503,\n",
       " 'congress': 504,\n",
       " 'lifted': 505,\n",
       " 'ceiling': 506,\n",
       " 'debt': 507,\n",
       " 'until': 508,\n",
       " 'acts': 509,\n",
       " 'authority': 510,\n",
       " 'issue': 511,\n",
       " 'obligations': 512,\n",
       " 'borrowing': 513,\n",
       " 'dropped': 514,\n",
       " 'midnight': 515,\n",
       " 'trillion': 516,\n",
       " 'legislation': 517,\n",
       " 'lift': 518,\n",
       " 'fight': 519,\n",
       " 'cutting': 520,\n",
       " 'capital-gains': 521,\n",
       " 'taxes': 522,\n",
       " 'house': 523,\n",
       " 'voted': 524,\n",
       " 'raise': 525,\n",
       " 'senate': 526,\n",
       " 'act': 527,\n",
       " 'next': 528,\n",
       " 'earliest': 529,\n",
       " 'default': 530,\n",
       " 'if': 531,\n",
       " 'then': 532,\n",
       " 'clark': 533,\n",
       " 'j.': 534,\n",
       " 'senior': 535,\n",
       " 'general': 536,\n",
       " 'manager': 537,\n",
       " 'marketing': 538,\n",
       " 'arm': 539,\n",
       " 'japanese': 540,\n",
       " 'auto': 541,\n",
       " 'maker': 542,\n",
       " 'mazda': 543,\n",
       " 'motor': 544,\n",
       " 'corp': 545,\n",
       " 'position': 546,\n",
       " 'oversee': 547,\n",
       " 'service': 548,\n",
       " 'previously': 549,\n",
       " 'chrysler': 550,\n",
       " 'division': 551,\n",
       " 'been': 552,\n",
       " 'executive': 553,\n",
       " 'when': 554,\n",
       " 'time': 555,\n",
       " 'their': 556,\n",
       " 'nation': 557,\n",
       " 'manufacturing': 558,\n",
       " 'jet': 559,\n",
       " 'off': 560,\n",
       " 'resort': 561,\n",
       " 'towns': 562,\n",
       " 'like': 563,\n",
       " 'hot': 564,\n",
       " 'springs': 565,\n",
       " 'not': 566,\n",
       " 'association': 567,\n",
       " 'manufacturers': 568,\n",
       " 'settled': 569,\n",
       " 'capital': 570,\n",
       " 'indianapolis': 571,\n",
       " 'fall': 572,\n",
       " 'meeting': 573,\n",
       " 'city': 574,\n",
       " 'decided': 575,\n",
       " 'treat': 576,\n",
       " 'guests': 577,\n",
       " 'royalty': 578,\n",
       " 'rock': 579,\n",
       " 'stars': 580,\n",
       " 'owners': 581,\n",
       " 'idea': 582,\n",
       " 'course': 583,\n",
       " 'prove': 584,\n",
       " 'corporate': 585,\n",
       " 'decision': 586,\n",
       " 'makers': 587,\n",
       " 'buckle': 588,\n",
       " 'belt': 589,\n",
       " 'so': 590,\n",
       " 'good': 591,\n",
       " 'expand': 592,\n",
       " 'receiving': 593,\n",
       " 'end': 594,\n",
       " 'message': 595,\n",
       " 'officials': 596,\n",
       " 'giants': 597,\n",
       " 'du': 598,\n",
       " 'pont': 599,\n",
       " 'along': 600,\n",
       " 'lesser': 601,\n",
       " 'steel': 602,\n",
       " 'valley': 603,\n",
       " 'queen': 604,\n",
       " 'executives': 605,\n",
       " 'joined': 606,\n",
       " 'mayor': 607,\n",
       " 'william': 608,\n",
       " 'h.': 609,\n",
       " 'iii': 610,\n",
       " 'evening': 611,\n",
       " 'guest': 612,\n",
       " 'victor': 613,\n",
       " 'champagne': 614,\n",
       " 'followed': 615,\n",
       " 'morning': 616,\n",
       " 'police': 617,\n",
       " 'wives': 618,\n",
       " 'traffic': 619,\n",
       " 'red': 620,\n",
       " 'lights': 621,\n",
       " 'governor': 622,\n",
       " 'could': 623,\n",
       " 'welcomed': 624,\n",
       " 'special': 625,\n",
       " 'buffet': 626,\n",
       " 'breakfast': 627,\n",
       " 'held': 628,\n",
       " 'museum': 629,\n",
       " 'food': 630,\n",
       " 'drinks': 631,\n",
       " 'banned': 632,\n",
       " 'everyday': 633,\n",
       " 'visitors': 634,\n",
       " 'honor': 635,\n",
       " 'out': 636,\n",
       " 'drivers': 637,\n",
       " 'crews': 638,\n",
       " 'official': 639,\n",
       " 'announcer': 640,\n",
       " 'exhibition': 641,\n",
       " 'race': 642,\n",
       " 'fortune': 643,\n",
       " 'cars': 644,\n",
       " 'pointed': 645,\n",
       " 'still': 646,\n",
       " 'space': 647,\n",
       " 'machines': 648,\n",
       " 'another': 649,\n",
       " 'sponsor': 650,\n",
       " 'name': 651,\n",
       " 'two': 652,\n",
       " 'back': 653,\n",
       " 'downtown': 654,\n",
       " 'squeezed': 655,\n",
       " 'meetings': 656,\n",
       " 'hotel': 657,\n",
       " 'buses': 658,\n",
       " 'dinner': 659,\n",
       " 'block': 660,\n",
       " 'away': 661,\n",
       " 'indiana': 662,\n",
       " 'nine': 663,\n",
       " 'hottest': 664,\n",
       " 'chefs': 665,\n",
       " 'town': 666,\n",
       " 'fed': 667,\n",
       " 'them': 668,\n",
       " 'knowing': 669,\n",
       " 'free': 670,\n",
       " 'eat': 671,\n",
       " 'gave': 672,\n",
       " 'standing': 673,\n",
       " 'say': 674,\n",
       " 'treatment': 675,\n",
       " 'return': 676,\n",
       " 'future': 677,\n",
       " 'looking': 678,\n",
       " 'forward': 679,\n",
       " 'winter': 680,\n",
       " 'february': 681,\n",
       " 'south': 682,\n",
       " 'korea': 683,\n",
       " 'registered': 684,\n",
       " 'trade': 685,\n",
       " 'deficit': 686,\n",
       " 'october': 687,\n",
       " 'reflecting': 688,\n",
       " 'country': 689,\n",
       " 'economic': 690,\n",
       " 'figures': 691,\n",
       " 'released': 692,\n",
       " 'wednesday': 693,\n",
       " 'ministry': 694,\n",
       " 'showed': 695,\n",
       " 'fifth': 696,\n",
       " 'monthly': 697,\n",
       " 'setback': 698,\n",
       " 'casting': 699,\n",
       " 'cloud': 700,\n",
       " 'economy': 701,\n",
       " 'exports': 702,\n",
       " 'stood': 703,\n",
       " 'mere': 704,\n",
       " 'increase': 705,\n",
       " 'while': 706,\n",
       " 'imports': 707,\n",
       " 'increased': 708,\n",
       " 'sharply': 709,\n",
       " 'last': 710,\n",
       " 'boom': 711,\n",
       " 'began': 712,\n",
       " 'prolonged': 713,\n",
       " 'labor': 714,\n",
       " 'disputes': 715,\n",
       " 'conflicts': 716,\n",
       " 'sluggish': 717,\n",
       " 'would': 718,\n",
       " 'remain': 719,\n",
       " 'target': 720,\n",
       " 'gloomy': 721,\n",
       " 'forecast': 722,\n",
       " 'recorded': 723,\n",
       " 'surplus': 724,\n",
       " 'january': 725,\n",
       " 'accumulated': 726,\n",
       " 'same': 727,\n",
       " 'newsweek': 728,\n",
       " 'trying': 729,\n",
       " 'keep': 730,\n",
       " 'pace': 731,\n",
       " 'rival': 732,\n",
       " 'magazine': 733,\n",
       " 'announced': 734,\n",
       " 'advertising': 735,\n",
       " 'introduce': 736,\n",
       " 'incentive': 737,\n",
       " 'plan': 738,\n",
       " 'advertisers': 739,\n",
       " 'ad': 740,\n",
       " 'washington': 741,\n",
       " 'post': 742,\n",
       " 'second': 743,\n",
       " 'offered': 744,\n",
       " 'plans': 745,\n",
       " 'give': 746,\n",
       " 'discounts': 747,\n",
       " 'maintaining': 748,\n",
       " 'increasing': 749,\n",
       " 'spending': 750,\n",
       " 'become': 751,\n",
       " 'permanent': 752,\n",
       " 'news': 753,\n",
       " 'underscore': 754,\n",
       " 'fierce': 755,\n",
       " 'competition': 756,\n",
       " 'between': 757,\n",
       " 'warner': 758,\n",
       " 'b.': 759,\n",
       " 'world': 760,\n",
       " 'alan': 761,\n",
       " 'full': 762,\n",
       " 'page': 763,\n",
       " 'cost': 764,\n",
       " 'mid-october': 765,\n",
       " 'lowered': 766,\n",
       " 'guaranteed': 767,\n",
       " 'circulation': 768,\n",
       " 'base': 769,\n",
       " 'lower': 770,\n",
       " 'effectively': 771,\n",
       " 'per': 772,\n",
       " 'subscriber': 773,\n",
       " 'costs': 774,\n",
       " 'yet': 775,\n",
       " 'announce': 776,\n",
       " 'credit': 777,\n",
       " 'credits': 778,\n",
       " 'renewal': 779,\n",
       " 'reward': 780,\n",
       " 'bonuses': 781,\n",
       " 'meet': 782,\n",
       " 'exceed': 783,\n",
       " 'long': 784,\n",
       " 'spent': 785,\n",
       " 'attempt': 786,\n",
       " 'shore': 787,\n",
       " 'decline': 788,\n",
       " 'pages': 789,\n",
       " 'months': 790,\n",
       " 'totaled': 791,\n",
       " 'drop': 792,\n",
       " 'publishers': 793,\n",
       " 'bureau': 794,\n",
       " 'what': 795,\n",
       " 'matters': 796,\n",
       " 'paying': 797,\n",
       " 'department': 798,\n",
       " 'doing': 799,\n",
       " 'fine': 800,\n",
       " 'both': 801,\n",
       " 'gaining': 802,\n",
       " 'without': 803,\n",
       " 'heavy': 804,\n",
       " 'use': 805,\n",
       " 'electronic': 806,\n",
       " 'subscribers': 807,\n",
       " 'telephones': 808,\n",
       " 'watches': 809,\n",
       " 'however': 810,\n",
       " 'none': 811,\n",
       " 'big': 812,\n",
       " 'gains': 813,\n",
       " 'audit': 814,\n",
       " 'largest': 815,\n",
       " 'decrease': 816,\n",
       " 'six': 817,\n",
       " 'flat': 818,\n",
       " 'electric': 819,\n",
       " 'system': 820,\n",
       " 'bowed': 821,\n",
       " 'bidding': 822,\n",
       " 'public': 823,\n",
       " 'hampshire': 824,\n",
       " 'saying': 825,\n",
       " 'risks': 826,\n",
       " 'too': 827,\n",
       " 'potential': 828,\n",
       " 'justify': 829,\n",
       " 'offer': 830,\n",
       " 'move': 831,\n",
       " 'leaves': 832,\n",
       " 'united': 833,\n",
       " 'illuminating': 834,\n",
       " 'northeast': 835,\n",
       " 'utilities': 836,\n",
       " 'outside': 837,\n",
       " 'bidders': 838,\n",
       " 'ps': 839,\n",
       " 'also': 840,\n",
       " 'proposed': 841,\n",
       " 'internal': 842,\n",
       " 'reorganization': 843,\n",
       " 'chapter': 844,\n",
       " 'bankruptcy': 845,\n",
       " 'proceedings': 846,\n",
       " 'independent': 847,\n",
       " 'acquire': 848,\n",
       " 'below': 849,\n",
       " 'value': 850,\n",
       " 'places': 851,\n",
       " 'bid': 852,\n",
       " 'says': 853,\n",
       " 'worth': 854,\n",
       " 'haven': 855,\n",
       " 'conn.': 856,\n",
       " 'hartford': 857,\n",
       " 'conn': 858,\n",
       " 'n.h.': 859,\n",
       " 'values': 860,\n",
       " 'john': 861,\n",
       " 'rowe': 862,\n",
       " 'chief': 863,\n",
       " 'officer': 864,\n",
       " 'equity': 865,\n",
       " 'suffer': 866,\n",
       " 'forecasts': 867,\n",
       " 'related': 868,\n",
       " 'growth': 869,\n",
       " 'electricity': 870,\n",
       " 'demand': 871,\n",
       " 'improved': 872,\n",
       " 'operating': 873,\n",
       " 'did': 874,\n",
       " 'come': 875,\n",
       " 'true': 876,\n",
       " 'raising': 877,\n",
       " 'seemed': 878,\n",
       " 'substantial': 879,\n",
       " 'persistent': 880,\n",
       " 'rewards': 881,\n",
       " 'way': 882,\n",
       " 'got': 883,\n",
       " 'hard': 884,\n",
       " 'take': 885,\n",
       " 'added': 886,\n",
       " 'noted': 887,\n",
       " 'political': 888,\n",
       " 'concerns': 889,\n",
       " 'worried': 890,\n",
       " 'matter': 891,\n",
       " 'owns': 892,\n",
       " 'emerges': 893,\n",
       " 'attracts': 894,\n",
       " 'just': 895,\n",
       " 'factors': 896,\n",
       " 'withdraw': 897,\n",
       " 'wilbur': 898,\n",
       " 'ross': 899,\n",
       " 'jr.': 900,\n",
       " 'rothschild': 901,\n",
       " 'adviser': 902,\n",
       " 'troubled': 903,\n",
       " 'holders': 904,\n",
       " 'withdrawal': 905,\n",
       " 'might': 906,\n",
       " 'speed': 907,\n",
       " 'fact': 908,\n",
       " 'increases': 909,\n",
       " 'against': 910,\n",
       " 'around': 911,\n",
       " 'complicated': 912,\n",
       " 'negotiations': 913,\n",
       " 'state': 914,\n",
       " 'asserted': 915,\n",
       " 'field': 916,\n",
       " 'less': 917,\n",
       " 'separately': 918,\n",
       " 'commission': 919,\n",
       " 'turned': 920,\n",
       " 'request': 921,\n",
       " 'seeking': 922,\n",
       " 'possible': 923,\n",
       " 'purchase': 924,\n",
       " 'hopes': 925,\n",
       " 'review': 926,\n",
       " 'ferc': 927,\n",
       " 'summer': 928,\n",
       " 'court': 929,\n",
       " 'shares': 930,\n",
       " 'closed': 931,\n",
       " 'yesterday': 932,\n",
       " 'cents': 933,\n",
       " 'york': 934,\n",
       " 'stock': 935,\n",
       " 'exchange': 936,\n",
       " 'composite': 937,\n",
       " 'trading': 938,\n",
       " 'norman': 939,\n",
       " 'toys': 940,\n",
       " 'r': 941,\n",
       " 'frederick': 942,\n",
       " 'banking': 943,\n",
       " 'directors': 944,\n",
       " 'consumer': 945,\n",
       " 'electronics': 946,\n",
       " 'appliances': 947,\n",
       " 'retailing': 948,\n",
       " 'chain': 949,\n",
       " 'succeed': 950,\n",
       " 'daniel': 951,\n",
       " 'm.': 952,\n",
       " 'retired': 953,\n",
       " 'circuit': 954,\n",
       " 'robert': 955,\n",
       " 'r.': 956,\n",
       " 'undersecretary': 957,\n",
       " 'commonwealth': 958,\n",
       " 'edison': 959,\n",
       " 'ordered': 960,\n",
       " 'refund': 961,\n",
       " 'illegal': 962,\n",
       " 'collected': 963,\n",
       " 'overruns': 964,\n",
       " 'nuclear': 965,\n",
       " 'power': 966,\n",
       " 'illinois': 967,\n",
       " 'commerce': 968,\n",
       " 'groups': 969,\n",
       " 'ever': 970,\n",
       " 'required': 971,\n",
       " 'local': 972,\n",
       " 'utility': 973,\n",
       " 'judge': 974,\n",
       " 'richard': 975,\n",
       " 'curry': 976,\n",
       " 'refunds': 977,\n",
       " 'each': 978,\n",
       " 'customers': 979,\n",
       " 'received': 980,\n",
       " 'april': 981,\n",
       " 'moved': 982,\n",
       " 'begin': 983,\n",
       " 'feb.': 984,\n",
       " 'appeals': 985,\n",
       " 'attempts': 986,\n",
       " 'his': 987,\n",
       " 'order': 988,\n",
       " 'pool': 989,\n",
       " 'through': 990,\n",
       " 'round': 991,\n",
       " 'already': 992,\n",
       " 'appealing': 993,\n",
       " 'underlying': 994,\n",
       " 'considering': 995,\n",
       " 'exact': 996,\n",
       " 'amount': 997,\n",
       " 'determined': 998,\n",
       " 'actual': 999,\n",
       " ...}"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_to_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-06T08:37:51.500608Z",
     "start_time": "2021-08-06T08:37:51.478665Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  1,  2, ..., 39, 26, 24])"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-06T08:40:18.915806Z",
     "start_time": "2021-08-06T08:40:18.906265Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  1,  2,  3,  4,  6,  7,  8,  9, 10])"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "contexts[0] # 윈도우 사이즈가 5라 id = 5 부터 시작"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-06T08:53:44.815749Z",
     "start_time": "2021-08-06T08:53:44.799894Z"
    }
   },
   "outputs": [],
   "source": [
    "class CBOW:\n",
    "    def __init__(self, vocab_size, hidden_size, window_size, corpus):\n",
    "        V, H = vocab_size, hidden_size\n",
    "\n",
    "        # 가중치 초기화\n",
    "        W_in = 0.01 * np.random.randn(V, H).astype('f')\n",
    "        W_out = 0.01 * np.random.randn(V, H).astype('f')\n",
    "\n",
    "        # 계층 생성\n",
    "        self.in_layers = []\n",
    "        for i in range(2 * window_size):\n",
    "            layer = Embedding(W_in)  # Embedding 계층 사용\n",
    "            self.in_layers.append(layer)\n",
    "        self.ns_loss = NegativeSamplingLoss(W_out, corpus, power=0.75, sample_size=5)\n",
    "\n",
    "        # 모든 가중치와 기울기를 배열에 모은다.\n",
    "        layers = self.in_layers + [self.ns_loss]\n",
    "        self.params, self.grads = [], []\n",
    "        for layer in layers:\n",
    "            self.params += layer.params\n",
    "            self.grads += layer.grads\n",
    "\n",
    "        # 인스턴스 변수에 단어의 분산 표현을 저장한다.\n",
    "        self.word_vecs = W_in\n",
    "\n",
    "    def forward(self, contexts, target):\n",
    "        h = 0\n",
    "        for i, layer in enumerate(self.in_layers):\n",
    "            h += layer.forward(contexts[:, i])\n",
    "        h *= 1 / len(self.in_layers)\n",
    "        loss = self.ns_loss.forward(h, target)\n",
    "        return loss\n",
    "\n",
    "\n",
    "    def backward(self, dout=1):\n",
    "        dout = self.ns_loss.backward(dout)\n",
    "        dout *= 1 / len(self.in_layers)\n",
    "        for layer in self.in_layers:\n",
    "            layer.backward(dout)\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-06T09:00:26.240408Z",
     "start_time": "2021-08-06T08:53:47.037102Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| 에폭 1 |  반복 1 / 9295 | 시간 0[s] | 손실 4.16\n",
      "| 에폭 1 |  반복 21 / 9295 | 시간 1[s] | 손실 4.16\n",
      "| 에폭 1 |  반복 41 / 9295 | 시간 3[s] | 손실 4.15\n",
      "| 에폭 1 |  반복 61 / 9295 | 시간 5[s] | 손실 4.12\n",
      "| 에폭 1 |  반복 81 / 9295 | 시간 6[s] | 손실 4.05\n",
      "| 에폭 1 |  반복 101 / 9295 | 시간 8[s] | 손실 3.92\n",
      "| 에폭 1 |  반복 121 / 9295 | 시간 9[s] | 손실 3.78\n",
      "| 에폭 1 |  반복 141 / 9295 | 시간 11[s] | 손실 3.63\n",
      "| 에폭 1 |  반복 161 / 9295 | 시간 13[s] | 손실 3.49\n",
      "| 에폭 1 |  반복 181 / 9295 | 시간 15[s] | 손실 3.37\n",
      "| 에폭 1 |  반복 201 / 9295 | 시간 17[s] | 손실 3.26\n",
      "| 에폭 1 |  반복 221 / 9295 | 시간 18[s] | 손실 3.17\n",
      "| 에폭 1 |  반복 241 / 9295 | 시간 21[s] | 손실 3.08\n",
      "| 에폭 1 |  반복 261 / 9295 | 시간 23[s] | 손실 3.03\n",
      "| 에폭 1 |  반복 281 / 9295 | 시간 24[s] | 손실 2.99\n",
      "| 에폭 1 |  반복 301 / 9295 | 시간 26[s] | 손실 2.93\n",
      "| 에폭 1 |  반복 321 / 9295 | 시간 28[s] | 손실 2.88\n",
      "| 에폭 1 |  반복 341 / 9295 | 시간 29[s] | 손실 2.83\n",
      "| 에폭 1 |  반복 361 / 9295 | 시간 31[s] | 손실 2.81\n",
      "| 에폭 1 |  반복 381 / 9295 | 시간 32[s] | 손실 2.78\n",
      "| 에폭 1 |  반복 401 / 9295 | 시간 34[s] | 손실 2.76\n",
      "| 에폭 1 |  반복 421 / 9295 | 시간 36[s] | 손실 2.75\n",
      "| 에폭 1 |  반복 441 / 9295 | 시간 38[s] | 손실 2.74\n",
      "| 에폭 1 |  반복 461 / 9295 | 시간 40[s] | 손실 2.71\n",
      "| 에폭 1 |  반복 481 / 9295 | 시간 41[s] | 손실 2.70\n",
      "| 에폭 1 |  반복 501 / 9295 | 시간 43[s] | 손실 2.72\n",
      "| 에폭 1 |  반복 521 / 9295 | 시간 45[s] | 손실 2.68\n",
      "| 에폭 1 |  반복 541 / 9295 | 시간 46[s] | 손실 2.67\n",
      "| 에폭 1 |  반복 561 / 9295 | 시간 49[s] | 손실 2.67\n",
      "| 에폭 1 |  반복 581 / 9295 | 시간 51[s] | 손실 2.67\n",
      "| 에폭 1 |  반복 601 / 9295 | 시간 53[s] | 손실 2.66\n",
      "| 에폭 1 |  반복 621 / 9295 | 시간 55[s] | 손실 2.65\n",
      "| 에폭 1 |  반복 641 / 9295 | 시간 58[s] | 손실 2.61\n",
      "| 에폭 1 |  반복 661 / 9295 | 시간 60[s] | 손실 2.61\n",
      "| 에폭 1 |  반복 681 / 9295 | 시간 62[s] | 손실 2.61\n",
      "| 에폭 1 |  반복 701 / 9295 | 시간 65[s] | 손실 2.63\n",
      "| 에폭 1 |  반복 721 / 9295 | 시간 67[s] | 손실 2.63\n",
      "| 에폭 1 |  반복 741 / 9295 | 시간 69[s] | 손실 2.61\n",
      "| 에폭 1 |  반복 761 / 9295 | 시간 71[s] | 손실 2.58\n",
      "| 에폭 1 |  반복 781 / 9295 | 시간 73[s] | 손실 2.58\n",
      "| 에폭 1 |  반복 801 / 9295 | 시간 74[s] | 손실 2.59\n",
      "| 에폭 1 |  반복 821 / 9295 | 시간 76[s] | 손실 2.59\n",
      "| 에폭 1 |  반복 841 / 9295 | 시간 78[s] | 손실 2.57\n",
      "| 에폭 1 |  반복 861 / 9295 | 시간 80[s] | 손실 2.59\n",
      "| 에폭 1 |  반복 881 / 9295 | 시간 82[s] | 손실 2.58\n",
      "| 에폭 1 |  반복 901 / 9295 | 시간 84[s] | 손실 2.57\n",
      "| 에폭 1 |  반복 921 / 9295 | 시간 86[s] | 손실 2.58\n",
      "| 에폭 1 |  반복 941 / 9295 | 시간 88[s] | 손실 2.56\n",
      "| 에폭 1 |  반복 961 / 9295 | 시간 90[s] | 손실 2.56\n",
      "| 에폭 1 |  반복 981 / 9295 | 시간 92[s] | 손실 2.53\n",
      "| 에폭 1 |  반복 1001 / 9295 | 시간 94[s] | 손실 2.54\n",
      "| 에폭 1 |  반복 1021 / 9295 | 시간 96[s] | 손실 2.54\n",
      "| 에폭 1 |  반복 1041 / 9295 | 시간 98[s] | 손실 2.53\n",
      "| 에폭 1 |  반복 1061 / 9295 | 시간 99[s] | 손실 2.52\n",
      "| 에폭 1 |  반복 1081 / 9295 | 시간 101[s] | 손실 2.53\n",
      "| 에폭 1 |  반복 1101 / 9295 | 시간 102[s] | 손실 2.53\n",
      "| 에폭 1 |  반복 1121 / 9295 | 시간 104[s] | 손실 2.54\n",
      "| 에폭 1 |  반복 1141 / 9295 | 시간 106[s] | 손실 2.55\n",
      "| 에폭 1 |  반복 1161 / 9295 | 시간 107[s] | 손실 2.58\n",
      "| 에폭 1 |  반복 1181 / 9295 | 시간 109[s] | 손실 2.53\n",
      "| 에폭 1 |  반복 1201 / 9295 | 시간 111[s] | 손실 2.55\n",
      "| 에폭 1 |  반복 1221 / 9295 | 시간 112[s] | 손실 2.52\n",
      "| 에폭 1 |  반복 1241 / 9295 | 시간 114[s] | 손실 2.54\n",
      "| 에폭 1 |  반복 1261 / 9295 | 시간 116[s] | 손실 2.53\n",
      "| 에폭 1 |  반복 1281 / 9295 | 시간 117[s] | 손실 2.55\n",
      "| 에폭 1 |  반복 1301 / 9295 | 시간 119[s] | 손실 2.53\n",
      "| 에폭 1 |  반복 1321 / 9295 | 시간 121[s] | 손실 2.55\n",
      "| 에폭 1 |  반복 1341 / 9295 | 시간 122[s] | 손실 2.52\n",
      "| 에폭 1 |  반복 1361 / 9295 | 시간 124[s] | 손실 2.51\n",
      "| 에폭 1 |  반복 1381 / 9295 | 시간 126[s] | 손실 2.55\n",
      "| 에폭 1 |  반복 1401 / 9295 | 시간 127[s] | 손실 2.52\n",
      "| 에폭 1 |  반복 1421 / 9295 | 시간 129[s] | 손실 2.51\n",
      "| 에폭 1 |  반복 1441 / 9295 | 시간 131[s] | 손실 2.51\n",
      "| 에폭 1 |  반복 1461 / 9295 | 시간 132[s] | 손실 2.49\n",
      "| 에폭 1 |  반복 1481 / 9295 | 시간 134[s] | 손실 2.53\n",
      "| 에폭 1 |  반복 1501 / 9295 | 시간 136[s] | 손실 2.53\n",
      "| 에폭 1 |  반복 1521 / 9295 | 시간 138[s] | 손실 2.55\n",
      "| 에폭 1 |  반복 1541 / 9295 | 시간 140[s] | 손실 2.51\n",
      "| 에폭 1 |  반복 1561 / 9295 | 시간 142[s] | 손실 2.48\n",
      "| 에폭 1 |  반복 1581 / 9295 | 시간 144[s] | 손실 2.51\n",
      "| 에폭 1 |  반복 1601 / 9295 | 시간 145[s] | 손실 2.54\n",
      "| 에폭 1 |  반복 1621 / 9295 | 시간 147[s] | 손실 2.50\n",
      "| 에폭 1 |  반복 1641 / 9295 | 시간 149[s] | 손실 2.53\n",
      "| 에폭 1 |  반복 1661 / 9295 | 시간 151[s] | 손실 2.52\n",
      "| 에폭 1 |  반복 1681 / 9295 | 시간 153[s] | 손실 2.48\n",
      "| 에폭 1 |  반복 1701 / 9295 | 시간 154[s] | 손실 2.47\n",
      "| 에폭 1 |  반복 1721 / 9295 | 시간 156[s] | 손실 2.50\n",
      "| 에폭 1 |  반복 1741 / 9295 | 시간 158[s] | 손실 2.51\n",
      "| 에폭 1 |  반복 1761 / 9295 | 시간 160[s] | 손실 2.51\n",
      "| 에폭 1 |  반복 1781 / 9295 | 시간 161[s] | 손실 2.48\n",
      "| 에폭 1 |  반복 1801 / 9295 | 시간 163[s] | 손실 2.50\n",
      "| 에폭 1 |  반복 1821 / 9295 | 시간 164[s] | 손실 2.50\n",
      "| 에폭 1 |  반복 1841 / 9295 | 시간 166[s] | 손실 2.50\n",
      "| 에폭 1 |  반복 1861 / 9295 | 시간 168[s] | 손실 2.50\n",
      "| 에폭 1 |  반복 1881 / 9295 | 시간 170[s] | 손실 2.51\n",
      "| 에폭 1 |  반복 1901 / 9295 | 시간 171[s] | 손실 2.51\n",
      "| 에폭 1 |  반복 1921 / 9295 | 시간 173[s] | 손실 2.50\n",
      "| 에폭 1 |  반복 1941 / 9295 | 시간 174[s] | 손실 2.50\n",
      "| 에폭 1 |  반복 1961 / 9295 | 시간 176[s] | 손실 2.49\n",
      "| 에폭 1 |  반복 1981 / 9295 | 시간 178[s] | 손실 2.50\n",
      "| 에폭 1 |  반복 2001 / 9295 | 시간 179[s] | 손실 2.49\n",
      "| 에폭 1 |  반복 2021 / 9295 | 시간 181[s] | 손실 2.50\n",
      "| 에폭 1 |  반복 2041 / 9295 | 시간 183[s] | 손실 2.51\n",
      "| 에폭 1 |  반복 2061 / 9295 | 시간 184[s] | 손실 2.49\n",
      "| 에폭 1 |  반복 2081 / 9295 | 시간 186[s] | 손실 2.49\n",
      "| 에폭 1 |  반복 2101 / 9295 | 시간 188[s] | 손실 2.48\n",
      "| 에폭 1 |  반복 2121 / 9295 | 시간 190[s] | 손실 2.50\n",
      "| 에폭 1 |  반복 2141 / 9295 | 시간 192[s] | 손실 2.49\n",
      "| 에폭 1 |  반복 2161 / 9295 | 시간 193[s] | 손실 2.49\n",
      "| 에폭 1 |  반복 2181 / 9295 | 시간 195[s] | 손실 2.48\n",
      "| 에폭 1 |  반복 2201 / 9295 | 시간 197[s] | 손실 2.49\n",
      "| 에폭 1 |  반복 2221 / 9295 | 시간 198[s] | 손실 2.49\n",
      "| 에폭 1 |  반복 2241 / 9295 | 시간 200[s] | 손실 2.53\n",
      "| 에폭 1 |  반복 2261 / 9295 | 시간 202[s] | 손실 2.46\n",
      "| 에폭 1 |  반복 2281 / 9295 | 시간 204[s] | 손실 2.48\n",
      "| 에폭 1 |  반복 2301 / 9295 | 시간 206[s] | 손실 2.51\n",
      "| 에폭 1 |  반복 2321 / 9295 | 시간 207[s] | 손실 2.49\n",
      "| 에폭 1 |  반복 2341 / 9295 | 시간 209[s] | 손실 2.49\n",
      "| 에폭 1 |  반복 2361 / 9295 | 시간 211[s] | 손실 2.46\n",
      "| 에폭 1 |  반복 2381 / 9295 | 시간 212[s] | 손실 2.47\n",
      "| 에폭 1 |  반복 2401 / 9295 | 시간 214[s] | 손실 2.46\n",
      "| 에폭 1 |  반복 2421 / 9295 | 시간 216[s] | 손실 2.47\n",
      "| 에폭 1 |  반복 2441 / 9295 | 시간 218[s] | 손실 2.46\n",
      "| 에폭 1 |  반복 2461 / 9295 | 시간 220[s] | 손실 2.46\n",
      "| 에폭 1 |  반복 2481 / 9295 | 시간 221[s] | 손실 2.49\n",
      "| 에폭 1 |  반복 2501 / 9295 | 시간 223[s] | 손실 2.44\n",
      "| 에폭 1 |  반복 2521 / 9295 | 시간 225[s] | 손실 2.46\n",
      "| 에폭 1 |  반복 2541 / 9295 | 시간 226[s] | 손실 2.46\n",
      "| 에폭 1 |  반복 2561 / 9295 | 시간 228[s] | 손실 2.45\n",
      "| 에폭 1 |  반복 2581 / 9295 | 시간 230[s] | 손실 2.49\n",
      "| 에폭 1 |  반복 2601 / 9295 | 시간 231[s] | 손실 2.47\n",
      "| 에폭 1 |  반복 2621 / 9295 | 시간 233[s] | 손실 2.47\n",
      "| 에폭 1 |  반복 2641 / 9295 | 시간 235[s] | 손실 2.45\n",
      "| 에폭 1 |  반복 2661 / 9295 | 시간 236[s] | 손실 2.47\n",
      "| 에폭 1 |  반복 2681 / 9295 | 시간 238[s] | 손실 2.47\n",
      "| 에폭 1 |  반복 2701 / 9295 | 시간 239[s] | 손실 2.47\n",
      "| 에폭 1 |  반복 2721 / 9295 | 시간 241[s] | 손실 2.46\n",
      "| 에폭 1 |  반복 2741 / 9295 | 시간 243[s] | 손실 2.47\n",
      "| 에폭 1 |  반복 2761 / 9295 | 시간 244[s] | 손실 2.45\n",
      "| 에폭 1 |  반복 2781 / 9295 | 시간 246[s] | 손실 2.47\n",
      "| 에폭 1 |  반복 2801 / 9295 | 시간 248[s] | 손실 2.44\n",
      "| 에폭 1 |  반복 2821 / 9295 | 시간 249[s] | 손실 2.44\n",
      "| 에폭 1 |  반복 2841 / 9295 | 시간 251[s] | 손실 2.46\n",
      "| 에폭 1 |  반복 2861 / 9295 | 시간 252[s] | 손실 2.48\n",
      "| 에폭 1 |  반복 2881 / 9295 | 시간 254[s] | 손실 2.45\n",
      "| 에폭 1 |  반복 2901 / 9295 | 시간 256[s] | 손실 2.45\n",
      "| 에폭 1 |  반복 2921 / 9295 | 시간 257[s] | 손실 2.48\n",
      "| 에폭 1 |  반복 2941 / 9295 | 시간 259[s] | 손실 2.44\n",
      "| 에폭 1 |  반복 2961 / 9295 | 시간 261[s] | 손실 2.45\n",
      "| 에폭 1 |  반복 2981 / 9295 | 시간 262[s] | 손실 2.45\n",
      "| 에폭 1 |  반복 3001 / 9295 | 시간 264[s] | 손실 2.46\n",
      "| 에폭 1 |  반복 3021 / 9295 | 시간 265[s] | 손실 2.43\n",
      "| 에폭 1 |  반복 3041 / 9295 | 시간 267[s] | 손실 2.43\n",
      "| 에폭 1 |  반복 3061 / 9295 | 시간 269[s] | 손실 2.42\n",
      "| 에폭 1 |  반복 3081 / 9295 | 시간 270[s] | 손실 2.45\n",
      "| 에폭 1 |  반복 3101 / 9295 | 시간 272[s] | 손실 2.44\n",
      "| 에폭 1 |  반복 3121 / 9295 | 시간 274[s] | 손실 2.46\n",
      "| 에폭 1 |  반복 3141 / 9295 | 시간 275[s] | 손실 2.47\n",
      "| 에폭 1 |  반복 3161 / 9295 | 시간 277[s] | 손실 2.45\n",
      "| 에폭 1 |  반복 3181 / 9295 | 시간 278[s] | 손실 2.41\n",
      "| 에폭 1 |  반복 3201 / 9295 | 시간 280[s] | 손실 2.43\n",
      "| 에폭 1 |  반복 3221 / 9295 | 시간 282[s] | 손실 2.46\n",
      "| 에폭 1 |  반복 3241 / 9295 | 시간 283[s] | 손실 2.44\n",
      "| 에폭 1 |  반복 3261 / 9295 | 시간 285[s] | 손실 2.44\n",
      "| 에폭 1 |  반복 3281 / 9295 | 시간 287[s] | 손실 2.42\n",
      "| 에폭 1 |  반복 3301 / 9295 | 시간 288[s] | 손실 2.43\n",
      "| 에폭 1 |  반복 3321 / 9295 | 시간 290[s] | 손실 2.43\n",
      "| 에폭 1 |  반복 3341 / 9295 | 시간 291[s] | 손실 2.42\n",
      "| 에폭 1 |  반복 3361 / 9295 | 시간 293[s] | 손실 2.42\n",
      "| 에폭 1 |  반복 3381 / 9295 | 시간 295[s] | 손실 2.44\n",
      "| 에폭 1 |  반복 3401 / 9295 | 시간 296[s] | 손실 2.43\n",
      "| 에폭 1 |  반복 3421 / 9295 | 시간 298[s] | 손실 2.46\n",
      "| 에폭 1 |  반복 3441 / 9295 | 시간 300[s] | 손실 2.43\n",
      "| 에폭 1 |  반복 3461 / 9295 | 시간 301[s] | 손실 2.39\n",
      "| 에폭 1 |  반복 3481 / 9295 | 시간 303[s] | 손실 2.43\n",
      "| 에폭 1 |  반복 3501 / 9295 | 시간 305[s] | 손실 2.43\n",
      "| 에폭 1 |  반복 3521 / 9295 | 시간 306[s] | 손실 2.39\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| 에폭 1 |  반복 3541 / 9295 | 시간 308[s] | 손실 2.40\n",
      "| 에폭 1 |  반복 3561 / 9295 | 시간 309[s] | 손실 2.41\n",
      "| 에폭 1 |  반복 3581 / 9295 | 시간 311[s] | 손실 2.41\n",
      "| 에폭 1 |  반복 3601 / 9295 | 시간 313[s] | 손실 2.42\n",
      "| 에폭 1 |  반복 3621 / 9295 | 시간 314[s] | 손실 2.39\n",
      "| 에폭 1 |  반복 3641 / 9295 | 시간 316[s] | 손실 2.42\n",
      "| 에폭 1 |  반복 3661 / 9295 | 시간 318[s] | 손실 2.43\n",
      "| 에폭 1 |  반복 3681 / 9295 | 시간 319[s] | 손실 2.40\n",
      "| 에폭 1 |  반복 3701 / 9295 | 시간 321[s] | 손실 2.42\n",
      "| 에폭 1 |  반복 3721 / 9295 | 시간 322[s] | 손실 2.43\n",
      "| 에폭 1 |  반복 3741 / 9295 | 시간 324[s] | 손실 2.40\n",
      "| 에폭 1 |  반복 3761 / 9295 | 시간 326[s] | 손실 2.39\n",
      "| 에폭 1 |  반복 3781 / 9295 | 시간 327[s] | 손실 2.39\n",
      "| 에폭 1 |  반복 3801 / 9295 | 시간 329[s] | 손실 2.42\n",
      "| 에폭 1 |  반복 3821 / 9295 | 시간 331[s] | 손실 2.43\n",
      "| 에폭 1 |  반복 3841 / 9295 | 시간 332[s] | 손실 2.42\n",
      "| 에폭 1 |  반복 3861 / 9295 | 시간 334[s] | 손실 2.42\n",
      "| 에폭 1 |  반복 3881 / 9295 | 시간 335[s] | 손실 2.40\n",
      "| 에폭 1 |  반복 3901 / 9295 | 시간 337[s] | 손실 2.42\n",
      "| 에폭 1 |  반복 3921 / 9295 | 시간 339[s] | 손실 2.40\n",
      "| 에폭 1 |  반복 3941 / 9295 | 시간 340[s] | 손실 2.44\n",
      "| 에폭 1 |  반복 3961 / 9295 | 시간 342[s] | 손실 2.39\n",
      "| 에폭 1 |  반복 3981 / 9295 | 시간 344[s] | 손실 2.42\n",
      "| 에폭 1 |  반복 4001 / 9295 | 시간 345[s] | 손실 2.38\n",
      "| 에폭 1 |  반복 4021 / 9295 | 시간 347[s] | 손실 2.39\n",
      "| 에폭 1 |  반복 4041 / 9295 | 시간 349[s] | 손실 2.36\n",
      "| 에폭 1 |  반복 4061 / 9295 | 시간 350[s] | 손실 2.42\n",
      "| 에폭 1 |  반복 4081 / 9295 | 시간 352[s] | 손실 2.38\n",
      "| 에폭 1 |  반복 4101 / 9295 | 시간 353[s] | 손실 2.37\n",
      "| 에폭 1 |  반복 4121 / 9295 | 시간 355[s] | 손실 2.39\n",
      "| 에폭 1 |  반복 4141 / 9295 | 시간 357[s] | 손실 2.41\n",
      "| 에폭 1 |  반복 4161 / 9295 | 시간 358[s] | 손실 2.38\n",
      "| 에폭 1 |  반복 4181 / 9295 | 시간 360[s] | 손실 2.36\n",
      "| 에폭 1 |  반복 4201 / 9295 | 시간 361[s] | 손실 2.38\n",
      "| 에폭 1 |  반복 4221 / 9295 | 시간 363[s] | 손실 2.35\n",
      "| 에폭 1 |  반복 4241 / 9295 | 시간 365[s] | 손실 2.38\n",
      "| 에폭 1 |  반복 4261 / 9295 | 시간 366[s] | 손실 2.37\n",
      "| 에폭 1 |  반복 4281 / 9295 | 시간 368[s] | 손실 2.38\n",
      "| 에폭 1 |  반복 4301 / 9295 | 시간 369[s] | 손실 2.39\n",
      "| 에폭 1 |  반복 4321 / 9295 | 시간 371[s] | 손실 2.40\n",
      "| 에폭 1 |  반복 4341 / 9295 | 시간 373[s] | 손실 2.39\n",
      "| 에폭 1 |  반복 4361 / 9295 | 시간 374[s] | 손실 2.37\n",
      "| 에폭 1 |  반복 4381 / 9295 | 시간 376[s] | 손실 2.40\n",
      "| 에폭 1 |  반복 4401 / 9295 | 시간 377[s] | 손실 2.43\n",
      "| 에폭 1 |  반복 4421 / 9295 | 시간 379[s] | 손실 2.40\n",
      "| 에폭 1 |  반복 4441 / 9295 | 시간 381[s] | 손실 2.37\n",
      "| 에폭 1 |  반복 4461 / 9295 | 시간 382[s] | 손실 2.40\n",
      "| 에폭 1 |  반복 4481 / 9295 | 시간 384[s] | 손실 2.38\n",
      "| 에폭 1 |  반복 4501 / 9295 | 시간 385[s] | 손실 2.40\n",
      "| 에폭 1 |  반복 4521 / 9295 | 시간 387[s] | 손실 2.37\n",
      "| 에폭 1 |  반복 4541 / 9295 | 시간 389[s] | 손실 2.37\n",
      "| 에폭 1 |  반복 4561 / 9295 | 시간 390[s] | 손실 2.37\n",
      "| 에폭 1 |  반복 4581 / 9295 | 시간 392[s] | 손실 2.35\n",
      "| 에폭 1 |  반복 4601 / 9295 | 시간 393[s] | 손실 2.37\n",
      "| 에폭 1 |  반복 4621 / 9295 | 시간 395[s] | 손실 2.35\n",
      "| 에폭 1 |  반복 4641 / 9295 | 시간 397[s] | 손실 2.40\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-125-c1ec6528d15c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;31m# 학습 시작\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mtrainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcontexts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_epoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Jupyter Notebook\\Deep Learning from Scratch\\common\\trainer.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, t, max_epoch, batch_size, max_grad, eval_interval)\u001b[0m\n\u001b[0;32m     42\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mmax_grad\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m                     \u001b[0mclip_grads\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrads\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_grad\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 44\u001b[1;33m                 \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrads\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     45\u001b[0m                 \u001b[0mtotal_loss\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m                 \u001b[0mloss_count\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Jupyter Notebook\\Deep Learning from Scratch\\common\\optimizer.py\u001b[0m in \u001b[0;36mupdate\u001b[1;34m(self, params, grads)\u001b[0m\n\u001b[0;32m    123\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    124\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 125\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mm\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbeta1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mgrads\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mm\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    126\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbeta2\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mgrads\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m**\u001b[0m\u001b[1;36m2\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    127\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 모델 등 생성\n",
    "model = CBOW(vocab_size, hidden_size, window_size, corpus)\n",
    "optimizer = Adam()\n",
    "trainer = Trainer(model, optimizer)\n",
    "\n",
    "# 학습 시작\n",
    "trainer.fit(contexts, target, max_epoch, batch_size)\n",
    "trainer.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 나중에 사용할 수 있도록 데이터 저장\n",
    "word_vecs = model.word_vecs\n",
    "params = {}\n",
    "params['word_vecs'] = word_vecs.astype(np.float16)\n",
    "params['word_to_id'] = word_to_id\n",
    "params['id_to_word'] = id_to_word\n",
    "pkl_file = 'cbow_params.pkl'\n",
    "wirh open(pkl_file, 'wb') as f :\n",
    "    pickle.dump(params, f, -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CBOW 모델 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-06T09:01:53.085857Z",
     "start_time": "2021-08-06T09:01:53.029387Z"
    }
   },
   "outputs": [],
   "source": [
    "from common.util import most_similar\n",
    "\n",
    "pkl_file = 'cbow_params.pkl'\n",
    "\n",
    "with open(pkl_file, 'rb') as f :\n",
    "    params = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-06T09:03:44.588963Z",
     "start_time": "2021-08-06T09:03:43.268582Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[query] you\n",
      " we: 0.6103515625\n",
      " someone: 0.59130859375\n",
      " i: 0.55419921875\n",
      " something: 0.48974609375\n",
      " anyone: 0.47314453125\n",
      "\n",
      "[query] year\n",
      " month: 0.71875\n",
      " week: 0.65234375\n",
      " spring: 0.62744140625\n",
      " summer: 0.6259765625\n",
      " decade: 0.603515625\n",
      "\n",
      "[query] car\n",
      " luxury: 0.497314453125\n",
      " arabia: 0.47802734375\n",
      " auto: 0.47119140625\n",
      " disk-drive: 0.450927734375\n",
      " travel: 0.4091796875\n",
      "\n",
      "[query] toyota\n",
      " ford: 0.55078125\n",
      " instrumentation: 0.509765625\n",
      " mazda: 0.49365234375\n",
      " bethlehem: 0.47509765625\n",
      " nissan: 0.474853515625\n"
     ]
    }
   ],
   "source": [
    "word_vecs = params['word_vecs']\n",
    "word_to_id = params['word_to_id']\n",
    "id_to_word = params['id_to_word']\n",
    "\n",
    "querys = ['you', 'year', 'car', 'toyota']\n",
    "for query in querys :\n",
    "    most_similar(query, word_to_id, id_to_word, word_vecs, top=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
